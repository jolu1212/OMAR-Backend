# Motor principal de chat con integraci√≥n a OpenAI GPT-4o-mini
import openai
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime
import json
import re

# Configurar logger para este m√≥dulo
logger = logging.getLogger(__name__)

class MotorChat:
    """
    Motor principal de conversaci√≥n que procesa consultas t√©cnicas
    y genera respuestas contextuales usando OpenAI GPT-4o-mini
    """
    
    def __init__(self, clave_api_openai: str):
        """
        Constructor del motor de chat
        Args:
            clave_api_openai: Clave de API de OpenAI para autenticaci√≥n
        """
        # Configurar cliente de OpenAI
        openai.api_key = clave_api_openai
        self.cliente_openai = openai
        
        # Configuraci√≥n espec√≠fica para respuestas t√©cnicas
        self.temperatura = 0.3          # Temperatura baja para respuestas m√°s precisas
        self.max_tokens = 1500          # L√≠mite de tokens por respuesta
        self.modelo = 'gpt-4o-mini'     # Modelo espec√≠fico para uso t√©cnico
        
        # Contexto especializado para ABB ACS150
        self.contexto_abb_acs150 = """
        Eres OMAR, un asistente t√©cnico especializado en el variador de frecuencia ABB ACS150.
        Tu funci√≥n es ayudar a t√©cnicos, operadores y supervisores industriales con:
        
        - Diagn√≥stico de problemas y fallas del variador ABB ACS150
        - Configuraci√≥n y parametrizaci√≥n del equipo
        - Procedimientos de mantenimiento preventivo y correctivo
        - Interpretaci√≥n de c√≥digos de error y alarmas
        - Gu√≠as de instalaci√≥n y conexi√≥n el√©ctrica
        - Optimizaci√≥n de par√°metros para diferentes aplicaciones
        
        INSTRUCCIONES IMPORTANTES:
        - Siempre proporciona respuestas t√©cnicas precisas y concisas
        - Usa terminolog√≠a t√©cnica apropiada pero explicada claramente
        - Si necesitas m√°s informaci√≥n, solicita clarificaci√≥n espec√≠fica
        - Prioriza la seguridad en todas las recomendaciones
        - Incluye referencias a c√≥digos de par√°metros cuando sea relevante
        - Responde en espa√±ol de manera profesional y t√©cnica
        """
        
        # Cache para respuestas frecuentes
        self.cache_respuestas = {}
        
        # Patrones para detectar tipos de consulta
        self.patrones_consulta = {
            'codigo_error': r'(error|falla|alarma|c√≥digo)\s*(\d+|[A-Z]+\d*)',
            'parametro': r'(par√°metro|param|P\d+|configurar)',
            'instalacion': r'(instalar|conexi√≥n|cableado|montaje)',
            'mantenimiento': r'(mantenimiento|limpieza|revisi√≥n|preventivo)',
            'diagnostico': r'(problema|no funciona|falla|diagn√≥stico)'
        }
        
        logger.info("MotorChat inicializado con modelo GPT-4o-mini para ABB ACS150")
    
    def procesar_consulta(self, consulta: str, id_sesion: str, contexto: Dict = None) -> Dict[str, Any]:
        """
        Procesa una consulta t√©cnica y genera respuesta contextual
        Args:
            consulta: Texto de la consulta del usuario
            id_sesion: ID de la sesi√≥n para contexto
            contexto: Informaci√≥n adicional de contexto
        Returns:
            Dict con la respuesta procesada
        """
        try:
            logger.info(f"Procesando consulta para sesi√≥n {id_sesion}: {consulta[:50]}...")
            
            # Verificar cache para respuestas frecuentes
            clave_cache = self._generar_clave_cache(consulta)
            if clave_cache in self.cache_respuestas:
                logger.debug(f"Respuesta encontrada en cache para: {clave_cache}")
                return self.cache_respuestas[clave_cache]
            
            # Detectar tipo de consulta
            tipo_consulta = self._detectar_tipo_consulta(consulta)
            
            # Construir prompt especializado
            prompt_completo = self._construir_prompt(consulta, tipo_consulta, contexto)
            
            # Llamar a OpenAI
            respuesta_openai = self._llamar_openai(prompt_completo)
            
            # Procesar y formatear respuesta
            respuesta_formateada = self._formatear_respuesta_tecnica(
                respuesta_openai, tipo_consulta
            )
            
            # Determinar si requiere clarificaci√≥n
            requiere_clarificacion = self._evaluar_necesidad_clarificacion(
                consulta, respuesta_openai
            )
            
            # Obtener contenido visual relacionado
            contenido_visual = self._obtener_contenido_visual(consulta, tipo_consulta)
            
            # Generar acciones sugeridas
            acciones_sugeridas = self._generar_acciones_sugeridas(tipo_consulta, consulta)
            
            # Construir respuesta final
            respuesta_final = {
                'mensaje': respuesta_formateada,
                'puntuacion_confianza': self._calcular_puntuacion_confianza(respuesta_openai),
                'contenido_visual': contenido_visual,
                'acciones_sugeridas': acciones_sugeridas,
                'requiere_clarificacion': requiere_clarificacion,
                'tipo_consulta': tipo_consulta,
                'timestamp': datetime.now().isoformat()
            }
            
            # Guardar en cache si es una respuesta de alta confianza
            if respuesta_final['puntuacion_confianza'] > 0.8:
                self.cache_respuestas[clave_cache] = respuesta_final
            
            logger.info(f"Consulta procesada exitosamente para sesi√≥n {id_sesion}")
            return respuesta_final
            
        except Exception as e:
            logger.error(f"Error procesando consulta: {str(e)}")
            return self._generar_respuesta_error(str(e))
    
    def _detectar_tipo_consulta(self, consulta: str) -> str:
        """
        Detecta el tipo de consulta basado en patrones de texto
        Args:
            consulta: Texto de la consulta
        Returns:
            Tipo de consulta detectado
        """
        consulta_lower = consulta.lower()
        
        # Verificar cada patr√≥n
        for tipo, patron in self.patrones_consulta.items():
            if re.search(patron, consulta_lower):
                logger.debug(f"Tipo de consulta detectado: {tipo}")
                return tipo
        
        # Tipo general si no se detecta patr√≥n espec√≠fico
        return 'general'
    
    def _construir_prompt(self, consulta: str, tipo_consulta: str, contexto: Dict = None) -> str:
        """
        Construye el prompt completo para OpenAI incluyendo contexto especializado
        Args:
            consulta: Consulta del usuario
            tipo_consulta: Tipo de consulta detectado
            contexto: Contexto adicional
        Returns:
            Prompt completo para OpenAI
        """
        # Prompt base con contexto ABB ACS150
        prompt = self.contexto_abb_acs150 + "\n\n"
        
        # A√±adir instrucciones espec√≠ficas seg√∫n tipo de consulta
        if tipo_consulta == 'codigo_error':
            prompt += """
            CONSULTA SOBRE C√ìDIGO DE ERROR:
            - Identifica el c√≥digo de error espec√≠fico
            - Explica la causa probable del error
            - Proporciona pasos de diagn√≥stico
            - Sugiere soluciones paso a paso
            - Incluye medidas preventivas
            """
        elif tipo_consulta == 'parametro':
            prompt += """
            CONSULTA SOBRE PAR√ÅMETROS:
            - Identifica el par√°metro espec√≠fico
            - Explica la funci√≥n del par√°metro
            - Proporciona rangos de valores recomendados
            - Incluye consideraciones de aplicaci√≥n
            - Menciona par√°metros relacionados
            """
        elif tipo_consulta == 'instalacion':
            prompt += """
            CONSULTA SOBRE INSTALACI√ìN:
            - Proporciona pasos de instalaci√≥n ordenados
            - Incluye consideraciones de seguridad
            - Especifica herramientas necesarias
            - Menciona verificaciones post-instalaci√≥n
            - Incluye diagramas de conexi√≥n si es relevante
            """
        
        # A√±adir contexto adicional si est√° disponible
        if contexto:
            prompt += f"\nCONTEXTO ADICIONAL:\n{json.dumps(contexto, indent=2)}\n"
        
        # A√±adir la consulta del usuario
        prompt += f"\nCONSULTA DEL USUARIO:\n{consulta}\n\n"
        prompt += "RESPUESTA T√âCNICA:"
        
        return prompt
    
    def _llamar_openai(self, prompt: str) -> str:
        """
        Realiza la llamada a la API de OpenAI
        Args:
            prompt: Prompt completo para enviar
        Returns:
            Respuesta de OpenAI
        """
        try:
            respuesta = self.cliente_openai.ChatCompletion.create(
                model=self.modelo,
                messages=[
                    {"role": "system", "content": "Eres OMAR, asistente t√©cnico especializado en ABB ACS150"},
                    {"role": "user", "content": prompt}
                ],
                temperature=self.temperatura,
                max_tokens=self.max_tokens,
                top_p=0.9,
                frequency_penalty=0.1,
                presence_penalty=0.1
            )
            
            return respuesta.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"Error en llamada a OpenAI: {str(e)}")
            # Respuesta de fallback
            return self._generar_respuesta_fallback()
    
    def _formatear_respuesta_tecnica(self, respuesta_cruda: str, tipo_consulta: str) -> str:
        """
        Formatea la respuesta para mejorar legibilidad t√©cnica
        Args:
            respuesta_cruda: Respuesta original de OpenAI
            tipo_consulta: Tipo de consulta para formateo espec√≠fico
        Returns:
            Respuesta formateada
        """
        # Limpiar y estructurar la respuesta
        respuesta = respuesta_cruda.strip()
        
        # A√±adir estructura seg√∫n tipo de consulta
        if tipo_consulta == 'codigo_error':
            # Asegurar estructura para c√≥digos de error
            if not re.search(r'(CAUSA|SOLUCI√ìN|DIAGN√ìSTICO)', respuesta, re.IGNORECASE):
                respuesta = f"üìã DIAGN√ìSTICO:\n{respuesta}"
        
        elif tipo_consulta == 'parametro':
            # Estructurar respuestas de par√°metros
            if not re.search(r'(PAR√ÅMETRO|RANGO|FUNCI√ìN)', respuesta, re.IGNORECASE):
                respuesta = f"‚öôÔ∏è CONFIGURACI√ìN DE PAR√ÅMETRO:\n{respuesta}"
        
        # A√±adir emojis t√©cnicos para mejor visualizaci√≥n
        respuesta = self._a√±adir_emojis_tecnicos(respuesta)
        
        return respuesta
    
    def _a√±adir_emojis_tecnicos(self, texto: str) -> str:
        """
        A√±ade emojis t√©cnicos para mejorar la visualizaci√≥n
        Args:
            texto: Texto original
        Returns:
            Texto con emojis t√©cnicos
        """
        # Mapeo de palabras t√©cnicas a emojis
        mapeo_emojis = {
            r'\b(error|falla|alarma)\b': '‚ö†Ô∏è \\1',
            r'\b(soluci√≥n|resolver)\b': '‚úÖ \\1',
            r'\b(par√°metro|configurar)\b': '‚öôÔ∏è \\1',
            r'\b(instalaci√≥n|conexi√≥n)\b': 'üîß \\1',
            r'\b(mantenimiento|revisi√≥n)\b': 'üõ†Ô∏è \\1',
            r'\b(seguridad|peligro)\b': 'üö® \\1',
            r'\b(voltaje|corriente|potencia)\b': '‚ö° \\1'
        }
        
        for patron, reemplazo in mapeo_emojis.items():
            texto = re.sub(patron, reemplazo, texto, flags=re.IGNORECASE)
        
        return texto
    
    def _evaluar_necesidad_clarificacion(self, consulta: str, respuesta: str) -> bool:
        """
        Eval√∫a si la consulta requiere clarificaci√≥n adicional
        Args:
            consulta: Consulta original
            respuesta: Respuesta generada
        Returns:
            True si requiere clarificaci√≥n
        """
        # Indicadores de consulta ambigua
        indicadores_ambiguedad = [
            'm√°s informaci√≥n', 'especificar', 'clarificar', 'detalles',
            'qu√© tipo', 'cu√°l modelo', 'en qu√© condiciones'
        ]
        
        # Verificar si la respuesta contiene indicadores de ambig√ºedad
        respuesta_lower = respuesta.lower()
        for indicador in indicadores_ambiguedad:
            if indicador in respuesta_lower:
                return True
        
        # Verificar si la consulta es muy corta o vaga
        if len(consulta.split()) < 3:
            return True
        
        return False
    
    def _obtener_contenido_visual(self, consulta: str, tipo_consulta: str) -> List[Dict]:
        """
        Obtiene referencias a contenido visual relacionado
        Args:
            consulta: Consulta del usuario
            tipo_consulta: Tipo de consulta
        Returns:
            Lista de referencias a im√°genes
        """
        contenido_visual = []
        
        # Mapeo de tipos de consulta a im√°genes relevantes
        if tipo_consulta == 'instalacion':
            contenido_visual.append({
                'id': 'abb_acs150_conexiones',
                'url': '/images/abb_acs150_diagrama_conexiones.png',
                'descripcion': 'Diagrama de conexiones ABB ACS150',
                'tags': ['instalacion', 'conexiones', 'diagrama']
            })
        
        elif tipo_consulta == 'codigo_error':
            contenido_visual.append({
                'id': 'abb_acs150_display',
                'url': '/images/abb_acs150_display_errores.png',
                'descripcion': 'Display de c√≥digos de error ABB ACS150',
                'tags': ['errores', 'display', 'codigos']
            })
        
        return contenido_visual
    
    def _generar_acciones_sugeridas(self, tipo_consulta: str, consulta: str) -> List[str]:
        """
        Genera acciones sugeridas basadas en el tipo de consulta
        Args:
            tipo_consulta: Tipo de consulta detectado
            consulta: Consulta original
        Returns:
            Lista de acciones sugeridas
        """
        acciones = []
        
        if tipo_consulta == 'codigo_error':
            acciones = [
                "Verificar conexiones el√©ctricas",
                "Revisar par√°metros de configuraci√≥n",
                "Consultar manual t√©cnico",
                "Contactar soporte t√©cnico si persiste"
            ]
        elif tipo_consulta == 'parametro':
            acciones = [
                "Respaldar configuraci√≥n actual",
                "Modificar par√°metro gradualmente",
                "Probar funcionamiento",
                "Documentar cambios realizados"
            ]
        elif tipo_consulta == 'instalacion':
            acciones = [
                "Verificar herramientas necesarias",
                "Revisar especificaciones t√©cnicas",
                "Seguir procedimientos de seguridad",
                "Realizar pruebas de funcionamiento"
            ]
        else:
            acciones = [
                "Proporcionar m√°s detalles espec√≠ficos",
                "Consultar documentaci√≥n t√©cnica",
                "Verificar estado del equipo"
            ]
        
        return acciones
    
    def _calcular_puntuacion_confianza(self, respuesta: str) -> float:
        """
        Calcula una puntuaci√≥n de confianza para la respuesta
        Args:
            respuesta: Respuesta generada
        Returns:
            Puntuaci√≥n de confianza entre 0 y 1
        """
        puntuacion = 0.5  # Puntuaci√≥n base
        
        # Factores que aumentan la confianza
        if len(respuesta) > 100:  # Respuesta detallada
            puntuacion += 0.1
        
        if re.search(r'(par√°metro|P\d+)', respuesta, re.IGNORECASE):  # Menciona par√°metros espec√≠ficos
            puntuacion += 0.2
        
        if re.search(r'(paso|procedimiento|instrucci√≥n)', respuesta, re.IGNORECASE):  # Incluye pasos
            puntuacion += 0.1
        
        if re.search(r'(seguridad|precauci√≥n|advertencia)', respuesta, re.IGNORECASE):  # Considera seguridad
            puntuacion += 0.1
        
        return min(puntuacion, 1.0)  # M√°ximo 1.0
    
    def _generar_clave_cache(self, consulta: str) -> str:
        """
        Genera una clave de cache para la consulta
        Args:
            consulta: Consulta del usuario
        Returns:
            Clave de cache normalizada
        """
        # Normalizar consulta para cache
        consulta_normalizada = re.sub(r'[^\w\s]', '', consulta.lower())
        palabras_clave = consulta_normalizada.split()[:5]  # Primeras 5 palabras
        return '_'.join(palabras_clave)
    
    def _generar_respuesta_fallback(self) -> str:
        """
        Genera una respuesta de fallback cuando OpenAI no est√° disponible
        Returns:
            Respuesta de fallback
        """
        return """
        üîß OMAR - Asistente T√©cnico ABB ACS150
        
        Actualmente experimento dificultades t√©cnicas para procesar tu consulta.
        
        üìã RECOMENDACIONES GENERALES:
        ‚Ä¢ Verifica las conexiones el√©ctricas del variador
        ‚Ä¢ Revisa que los par√°metros b√°sicos est√©n configurados correctamente
        ‚Ä¢ Consulta el manual t√©cnico ABB ACS150 para procedimientos espec√≠ficos
        ‚Ä¢ Si el problema persiste, contacta al soporte t√©cnico
        
        ‚ö†Ô∏è IMPORTANTE: Siempre sigue los procedimientos de seguridad antes de realizar cualquier intervenci√≥n.
        
        Intenta tu consulta nuevamente en unos momentos.
        """
    
    def _generar_respuesta_error(self, error: str) -> Dict[str, Any]:
        """
        Genera una respuesta de error estructurada
        Args:
            error: Mensaje de error
        Returns:
            Respuesta de error formateada
        """
        return {
            'mensaje': self._generar_respuesta_fallback(),
            'puntuacion_confianza': 0.0,
            'contenido_visual': [],
            'acciones_sugeridas': [
                "Verificar conexi√≥n a internet",
                "Intentar nuevamente en unos momentos",
                "Contactar soporte t√©cnico si el problema persiste"
            ],
            'requiere_clarificacion': False,
            'tipo_consulta': 'error',
            'timestamp': datetime.now().isoformat(),
            'error_tecnico': error
        }